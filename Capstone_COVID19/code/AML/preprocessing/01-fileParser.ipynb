{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import os\r\n",
        "import glob\r\n",
        "from tqdm import tqdm\r\n",
        "from numpy import asarray, save, load\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from matplotlib.pyplot import imshow\r\n",
        "from PIL import Image\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import shutil\r\n",
        "from shutil import copy\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "from tensorflow.keras import models\r\n",
        "from tensorflow.keras import optimizers\r\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\r\n",
        "from timeit import default_timer as timer\r\n",
        "from azure.storage.blob import BlobClient\r\n",
        "\r\n",
        "%matplotlib inline\r\n",
        "pd.set_option('display.max_colwidth', 500)\r\n"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1641487129939
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount ADLS"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Mount Function"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mountADLS():\r\n",
        "    # azureml-core of version 1.0.72 or higher is required\r\n",
        "    from azureml.core import Workspace, Dataset\r\n",
        "\r\n",
        "    subscription_id = 'xxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxx'\r\n",
        "    resource_group = 'Your Azure RG'\r\n",
        "    workspace_name = 'Azure ML Workspace Name'\r\n",
        "    dataset_name = 'Name of your dataset in Azure ML'\r\n",
        "\r\n",
        "    workspace = Workspace(subscription_id, resource_group, workspace_name)\r\n",
        "\r\n",
        "    dataset = Dataset.get_by_name(workspace, name=dataset_name)\r\n",
        "\r\n",
        "    # Create mountcontext and mount the dataset\r\n",
        "    mount_ctx = dataset.mount()  \r\n",
        "    mount_ctx.start()  \r\n",
        "\r\n",
        "    # Get the mount point\r\n",
        "    dataset_mount_folder = mount_ctx.mount_point\r\n",
        "    print(dataset_mount_folder)\r\n",
        "\r\n",
        "    # List the files in the mount point\r\n",
        "    files = os.listdir(dataset_mount_folder)\r\n",
        "    print(files)\r\n",
        "    return dataset_mount_folder\r\n",
        "    "
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1641487238461
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount ADLS to Compute Instance"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mount = mountADLS()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/tmp/tmpbq9_o0tg\n[\"Phil's Upload\", \"Robin's Upload\", 'TrainTestSetsBalanced', 'TrainTestSetsBalancedGreyscale', 'balancedSets', 'balancedSetsGreyscale', 'processed']\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1641487331474
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select Root Folder"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the root folder in Azure Data Lake that we want to work with\r\n",
        "root = mount+\"/Phil's Upload/\""
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1641487351735
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parse Folders/Files"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Parsing & DataFrame Functions "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to parse the folders in the root subdirectories\r\n",
        "def folderParser(root: str) -> list:\r\n",
        "    folderList = []\r\n",
        "    finalList = []\r\n",
        "    rootFolders = glob.glob(root+'*/')\r\n",
        "    for folder in rootFolders:\r\n",
        "        if 'archive 2' not in folder:\r\n",
        "            folderList.append(glob.glob(folder+'/*'))\r\n",
        "    for folder in folderList:\r\n",
        "        for item in folder:\r\n",
        "            finalList.append(glob.glob(item+'/*'))\r\n",
        "    return finalList\r\n",
        "\r\n",
        "\r\n",
        "# Function that creates a columnar dataframe from the folderParser function output\r\n",
        "def dataframeCreation(folderlist: list) -> pd.DataFrame:\r\n",
        "    healthySeries = []\r\n",
        "    covidSeries = []\r\n",
        "    pneumoniaSeries = []\r\n",
        "    for l in folderlist:\r\n",
        "        for item in l:\r\n",
        "            if 'NORMAL' in item:\r\n",
        "                healthySeries.append(item)\r\n",
        "            elif 'COVID' in item:\r\n",
        "                covidSeries.append(item)\r\n",
        "            elif 'PNEUMONIA' in item:\r\n",
        "                pneumoniaSeries.append(item)\r\n",
        "    dictcol = {'healthy':healthySeries,'pneumonia':pneumoniaSeries,'covid':covidSeries}\r\n",
        "    df = pd.DataFrame.from_dict(dictcol, orient='index')\r\n",
        "    df = df.transpose()\r\n",
        "    return df\r\n"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1641487437840
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parse Root Folder"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create list from the folderParser function\r\n",
        "folderlist = folderParser(root)"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1641487441639
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folderlist"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "[[\"/tmp/tmpbq9_o0tg/Phil's Upload/archive/test/NORMAL\",\n  \"/tmp/tmpbq9_o0tg/Phil's Upload/archive/test/PNEUMONIA\"],\n [\"/tmp/tmpbq9_o0tg/Phil's Upload/archive/train/NORMAL\",\n  \"/tmp/tmpbq9_o0tg/Phil's Upload/archive/train/PNEUMONIA\"],\n [\"/tmp/tmpbq9_o0tg/Phil's Upload/archive/val/NORMAL\",\n  \"/tmp/tmpbq9_o0tg/Phil's Upload/archive/val/PNEUMONIA\"],\n [\"/tmp/tmpbq9_o0tg/Phil's Upload/archive 1/test/COVID19\",\n  \"/tmp/tmpbq9_o0tg/Phil's Upload/archive 1/test/NORMAL\",\n  \"/tmp/tmpbq9_o0tg/Phil's Upload/archive 1/test/PNEUMONIA\"],\n [\"/tmp/tmpbq9_o0tg/Phil's Upload/archive 1/train/COVID19\",\n  \"/tmp/tmpbq9_o0tg/Phil's Upload/archive 1/train/NORMAL\",\n  \"/tmp/tmpbq9_o0tg/Phil's Upload/archive 1/train/PNEUMONIA\"]]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1641487448832
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Dataframe of Subfolders"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass list from folderParser into dataframe creation function\r\n",
        "df = dataframeCreation(folderlist)"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1641487468651
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "                                                 healthy  \\\n0     /tmp/tmpbq9_o0tg/Phil's Upload/archive/test/NORMAL   \n1    /tmp/tmpbq9_o0tg/Phil's Upload/archive/train/NORMAL   \n2      /tmp/tmpbq9_o0tg/Phil's Upload/archive/val/NORMAL   \n3   /tmp/tmpbq9_o0tg/Phil's Upload/archive 1/test/NORMAL   \n4  /tmp/tmpbq9_o0tg/Phil's Upload/archive 1/train/NORMAL   \n\n                                                  pneumonia  \\\n0     /tmp/tmpbq9_o0tg/Phil's Upload/archive/test/PNEUMONIA   \n1    /tmp/tmpbq9_o0tg/Phil's Upload/archive/train/PNEUMONIA   \n2      /tmp/tmpbq9_o0tg/Phil's Upload/archive/val/PNEUMONIA   \n3   /tmp/tmpbq9_o0tg/Phil's Upload/archive 1/test/PNEUMONIA   \n4  /tmp/tmpbq9_o0tg/Phil's Upload/archive 1/train/PNEUMONIA   \n\n                                                    covid  \n0   /tmp/tmpbq9_o0tg/Phil's Upload/archive 1/test/COVID19  \n1  /tmp/tmpbq9_o0tg/Phil's Upload/archive 1/train/COVID19  \n2                                                    None  \n3                                                    None  \n4                                                    None  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>healthy</th>\n      <th>pneumonia</th>\n      <th>covid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/tmp/tmpbq9_o0tg/Phil's Upload/archive/test/NORMAL</td>\n      <td>/tmp/tmpbq9_o0tg/Phil's Upload/archive/test/PNEUMONIA</td>\n      <td>/tmp/tmpbq9_o0tg/Phil's Upload/archive 1/test/COVID19</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/tmp/tmpbq9_o0tg/Phil's Upload/archive/train/NORMAL</td>\n      <td>/tmp/tmpbq9_o0tg/Phil's Upload/archive/train/PNEUMONIA</td>\n      <td>/tmp/tmpbq9_o0tg/Phil's Upload/archive 1/train/COVID19</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/tmp/tmpbq9_o0tg/Phil's Upload/archive/val/NORMAL</td>\n      <td>/tmp/tmpbq9_o0tg/Phil's Upload/archive/val/PNEUMONIA</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/tmp/tmpbq9_o0tg/Phil's Upload/archive 1/test/NORMAL</td>\n      <td>/tmp/tmpbq9_o0tg/Phil's Upload/archive 1/test/PNEUMONIA</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/tmp/tmpbq9_o0tg/Phil's Upload/archive 1/train/NORMAL</td>\n      <td>/tmp/tmpbq9_o0tg/Phil's Upload/archive 1/train/PNEUMONIA</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1641487470633
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Preprocessing"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resize, Convert, Normalize"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "healthyTestArray = []\r\n",
        "healthyTestLabels = []\r\n",
        "healthyTrainArray = []\r\n",
        "healthyTrainLabels = []\r\n",
        "pneumoniaTestArray = []\r\n",
        "pneumoniaTestLabels = []\r\n",
        "pneumoniaTrainArray = []\r\n",
        "pneumoniaTrainLabels = []\r\n",
        "covidTestArray = []\r\n",
        "covidTestLabels = []\r\n",
        "covidTrainArray = []\r\n",
        "covidTrainLabels = []\r\n",
        "\r\n",
        "for name in df.columns:\r\n",
        "    for folder in df[name]:\r\n",
        "        if folder is not None:\r\n",
        "            if 'NORMAL' in folder:\r\n",
        "                if 'train' in folder:\r\n",
        "                    f = glob.glob(folder+'/*')\r\n",
        "                    for image in f:\r\n",
        "                        img = load_img(image, target_size = (300,300))\r\n",
        "                        img = img_to_array(img)\r\n",
        "                        img = np.divide(img,255.)\r\n",
        "                        healthyTrainArray.append(img)\r\n",
        "                        healthyTrainLabels.append(0)\r\n",
        "                else:\r\n",
        "                    f = glob.glob(folder+'/*')\r\n",
        "                    for image in f:\r\n",
        "                        img = load_img(image, target_size = (300,300))\r\n",
        "                        img = img_to_array(img)\r\n",
        "                        img = np.divide(img,255.)\r\n",
        "                        healthyTestArray.append(img)\r\n",
        "                        healthyTestLabels.append(0)\r\n",
        "            if 'PNEUMONIA' in folder:\r\n",
        "                if 'train' in folder:\r\n",
        "                    f = glob.glob(folder+'/*')\r\n",
        "                    for image in f:\r\n",
        "                        img = load_img(image, target_size = (300,300))\r\n",
        "                        img = img_to_array(img)\r\n",
        "                        img = np.divide(img,255.)\r\n",
        "                        pneumoniaTrainArray.append(img)\r\n",
        "                        pneumoniaTrainLabels.append(1)\r\n",
        "                else:\r\n",
        "                    f = glob.glob(folder+'/*')\r\n",
        "                    for image in f:\r\n",
        "                        img = load_img(image, target_size = (300,300))\r\n",
        "                        img = img_to_array(img)\r\n",
        "                        img = np.divide(img,255.)\r\n",
        "                        pneumoniaTestArray.append(img)\r\n",
        "                        pneumoniaTestLabels.append(1)\r\n",
        "            if 'COVID' in folder:\r\n",
        "                if 'train' in folder:\r\n",
        "                    f = glob.glob(folder+'/*')\r\n",
        "                    for image in f:\r\n",
        "                        img = load_img(image, target_size = (300,300))\r\n",
        "                        img = img_to_array(img)\r\n",
        "                        img = np.divide(img,255.)\r\n",
        "                        covidTrainArray.append(img)\r\n",
        "                        covidTrainLabels.append(2)\r\n",
        "                else:\r\n",
        "                    f = glob.glob(folder+'/*')\r\n",
        "                    for image in f:\r\n",
        "                        img = load_img(image, target_size = (300,300))\r\n",
        "                        img = img_to_array(img)\r\n",
        "                        img = np.divide(img,255.)\r\n",
        "                        covidTestArray.append(img)\r\n",
        "                        covidTestLabels.append(2)"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1634783489567
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert Lists to NumPy Arrays"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "healthyTEA = np.asarray(healthyTestArray)\r\n",
        "healthyTEL = np.asarray(healthyTestLabels)\r\n",
        "healthyTRA = np.asarray(healthyTrainArray)\r\n",
        "healthyTRL = np.asarray(healthyTrainLabels)\r\n",
        "pneumoniaTEA = np.asarray(pneumoniaTestArray)\r\n",
        "pneumoniaTEL = np.asarray(pneumoniaTestLabels)\r\n",
        "pneumoniaTRA = np.asarray(pneumoniaTrainArray)\r\n",
        "pneumoniaTRL = np.asarray(pneumoniaTrainLabels)\r\n",
        "covidTEA = np.asarray(covidTestArray)\r\n",
        "covidTEL = np.asarray(covidTestLabels)\r\n",
        "covidTRA = np.asarray(covidTrainArray)\r\n",
        "covidTRL = np.asarray(covidTrainLabels)"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1634785402395
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save NumPy Arrays To Current Directory"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('healthyTestArray',healthyTEA)\r\n",
        "np.save('healthyTestLabels',healthyTEL)\r\n",
        "np.save('healthyTrainArray',healthyTRA)\r\n",
        "np.save('healthyTrainLabels',healthyTRL)\r\n",
        "np.save('pneumoniaTestArray',pneumoniaTEA)\r\n",
        "np.save('pneumoniaTestLabels',pneumoniaTEL)\r\n",
        "np.save('pneumoniaTrainArray',pneumoniaTRA)\r\n",
        "np.save('pneumoniaTrainLabels',pneumoniaTRL)\r\n",
        "np.save('covidTestArray',covidTEA)\r\n",
        "np.save('covidTestLabels',covidTEL)\r\n",
        "np.save('covidTrainArray',covidTRA)\r\n",
        "np.save('covidTrainLabels',covidTRL)"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1634785513328
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload Arrays to Azure Data Lake \"processed\" Folder"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "storage_account_key = input(\"enter storage account key\")\r\n",
        "\r\n",
        "storage_url = \"https://{storageaccountname}.blob.core.windows.net/\" \r\n",
        "\r\n",
        "arraynames = []\r\n",
        "for f in os.listdir():\r\n",
        "    if '.npy' in f:\r\n",
        "        arraynames.append(f)\r\n",
        "        \r\n",
        "for a in arraynames:\r\n",
        "    blob_client = BlobClient(storage_url, container_name=\"images/processed/arrays\", blob_name=a, credential=storage_account_key)\r\n",
        "    with open(a, \"rb\") as data:\r\n",
        "        blob_client.upload_blob(data)"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1634260928330
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}